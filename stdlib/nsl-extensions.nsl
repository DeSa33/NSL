# ============================================
# NSL STANDARD LIBRARY EXTENSIONS
# Version: 1.0.0
# ============================================
# This library extends NSL with:
# - GPU helper operations (sum, mean, std, etc.)
# - Consciousness operator utilities
# - Enhanced error handling helpers
# ============================================

# ============================================
# SECTION 1: GPU HELPER OPERATIONS
# ============================================

fn gpu_sum(arr) {
    # Sum all elements from a GPU tensor (after to_cpu)
    mut total = 0.0
    for val in arr {
        total = total + val
    }
    return total
}

fn gpu_mean(arr) {
    # Calculate mean of array
    return gpu_sum(arr) / len(arr)
}

fn gpu_min(arr) {
    # Find minimum value
    mut m = arr[0]
    for val in arr {
        if val < m {
            m = val
        }
    }
    return m
}

fn gpu_max(arr) {
    # Find maximum value
    mut m = arr[0]
    for val in arr {
        if val > m {
            m = val
        }
    }
    return m
}

fn gpu_std(arr) {
    # Standard deviation
    let m = gpu_mean(arr)
    let n = len(arr)
    mut sum_sq = 0.0
    for val in arr {
        let diff = val - m
        sum_sq = sum_sq + diff * diff
    }
    return sqrt(sum_sq / n)
}

fn gpu_variance(arr) {
    # Variance (std squared)
    let s = gpu_std(arr)
    return s * s
}

fn gpu_normalize(arr) {
    # Normalize array to [0, 1] range
    let min_v = gpu_min(arr)
    let max_v = gpu_max(arr)
    let range_v = max_v - min_v
    if range_v == 0 {
        return arr
    }
    mut result = []
    for val in arr {
        result = result + [(val - min_v) / range_v]
    }
    return result
}

fn gpu_standardize(arr) {
    # Standardize to mean=0, std=1 (z-score)
    let m = gpu_mean(arr)
    let s = gpu_std(arr)
    if s == 0 {
        return arr
    }
    mut result = []
    for val in arr {
        result = result + [(val - m) / s]
    }
    return result
}

fn gpu_argmax(arr) {
    # Index of maximum value
    mut max_idx = 0
    mut max_val = arr[0]
    for i in 0..len(arr) {
        if arr[i] > max_val {
            max_val = arr[i]
            max_idx = i
        }
    }
    return max_idx
}

fn gpu_argmin(arr) {
    # Index of minimum value
    mut min_idx = 0
    mut min_val = arr[0]
    for i in 0..len(arr) {
        if arr[i] < min_val {
            min_val = arr[i]
            min_idx = i
        }
    }
    return min_idx
}

fn gpu_dot(a, b) {
    # Dot product of two arrays
    mut result = 0.0
    for i in 0..len(a) {
        result = result + a[i] * b[i]
    }
    return result
}

fn gpu_l2_norm(arr) {
    # L2 norm (Euclidean length)
    return sqrt(gpu_dot(arr, arr))
}

fn gpu_cosine_similarity(a, b) {
    # Cosine similarity between two vectors
    let dot_prod = gpu_dot(a, b)
    let norm_a = gpu_l2_norm(a)
    let norm_b = gpu_l2_norm(b)
    if norm_a == 0 or norm_b == 0 {
        return 0.0
    }
    return dot_prod / (norm_a * norm_b)
}

# ============================================
# SECTION 2: CONSCIOUSNESS OPERATOR HELPERS
# ============================================

# |> PIPE: Chain transformations left-to-right
fn pipe_chain(value, fns) {
    # Apply a list of functions in sequence
    mut result = value
    for f in fns {
        result = f(result)
    }
    return result
}

# ◈ HOLOGRAPHIC: Attention/focus mechanism
fn holographic_focus(data, weights) {
    # Apply attention weights to data
    if len(data) != len(weights) {
        return err("Data and weights must have same length")
    }
    mut result = []
    mut weight_sum = 0.0
    for w in weights {
        weight_sum = weight_sum + w
    }
    for i in 0..len(data) {
        let normalized_weight = weights[i] / weight_sum
        result = result + [data[i] * normalized_weight]
    }
    return ok(result)
}

# ∇ GRADIENT: Learning/adjustment with feedback
fn gradient_step(params, grads, learning_rate) {
    # Update parameters using gradients
    mut new_params = []
    for i in 0..len(params) {
        new_params = new_params + [params[i] - learning_rate * grads[i]]
    }
    return new_params
}

fn gradient_descent(params, loss_fn, lr, steps) {
    # Simple gradient descent optimization
    mut current = params
    for step in 0..steps {
        let loss = loss_fn(current)
        # Numerical gradient approximation
        let eps = 0.0001
        mut grads = []
        for i in 0..len(current) {
            mut p_plus = []
            mut p_minus = []
            for j in 0..len(current) {
                if j == i {
                    p_plus = p_plus + [current[j] + eps]
                    p_minus = p_minus + [current[j] - eps]
                } else {
                    p_plus = p_plus + [current[j]]
                    p_minus = p_minus + [current[j]]
                }
            }
            let grad = (loss_fn(p_plus) - loss_fn(p_minus)) / (2 * eps)
            grads = grads + [grad]
        }
        current = gradient_step(current, grads, lr)
    }
    return current
}

# Ψ SUPERPOSITION: Hold multiple states simultaneously
fn superposition_create(states, amplitudes) {
    # Create a superposition of states with amplitudes
    if len(states) != len(amplitudes) {
        return err("States and amplitudes must match")
    }
    # Normalize amplitudes (squared sum = 1)
    mut sum_sq = 0.0
    for amp in amplitudes {
        sum_sq = sum_sq + amp * amp
    }
    let norm_factor = sqrt(sum_sq)
    mut normalized = []
    mut probs = []
    for amp in amplitudes {
        let n = amp / norm_factor
        normalized = normalized + [n]
        probs = probs + [n * n]
    }
    return ok([states, normalized, probs])
}

fn superposition_collapse(superpos) {
    # Collapse superposition to single state (probabilistic)
    # superpos is [states, amplitudes, probabilities]
    let r = random()
    mut cumulative = 0.0
    let probs = superpos[2]
    let states = superpos[0]
    for i in 0..len(probs) {
        cumulative = cumulative + probs[i]
        if r <= cumulative {
            return states[i]
        }
    }
    return states[len(states) - 1]
}

# μ MEMORY: Persistent state across operations
fn memory_create() {
    # Create a memory store as [keys, values, history]
    return [[], [], []]
}

fn memory_store(store, key, value) {
    # Store value in memory
    let keys = store[0]
    let vals = store[1]
    let hist = store[2]
    # Check if key exists
    for i in 0..len(keys) {
        if keys[i] == key {
            vals[i] = value
            return [keys, vals, hist + [key]]
        }
    }
    return [keys + [key], vals + [value], hist + [key]]
}

fn memory_recall(store, key) {
    # Recall value from memory
    let keys = store[0]
    let vals = store[1]
    for i in 0..len(keys) {
        if keys[i] == key {
            return some(vals[i])
        }
    }
    return none()
}

# σ INTROSPECTION: Self-reflection capabilities
fn introspect_value(val) {
    # Return the value itself (for inspection)
    return val
}

fn introspect_array(arr) {
    # Get statistics about an array
    # Returns [length, min, max, mean, std, sum]
    let n = len(arr)
    let min_v = gpu_min(arr)
    let max_v = gpu_max(arr)
    let mean_v = gpu_mean(arr)
    let std_v = gpu_std(arr)
    let sum_v = gpu_sum(arr)
    return [n, min_v, max_v, mean_v, std_v, sum_v]
}

# ============================================
# SECTION 3: ENHANCED ERROR HANDLING
# ============================================

fn try_default(operation, fallback) {
    # Attempt operation, return fallback on error
    let result = operation()
    if is_err(result) {
        return fallback
    }
    return unwrap(result)
}

fn validate_array_length(arr, min_len, max_len) {
    # Validate array length
    let n = len(arr)
    if n < min_len {
        return err("Array too short")
    }
    if n > max_len {
        return err("Array too long")
    }
    return ok(arr)
}

fn validate_range(val, min_val, max_val, name) {
    # Validate value is in range
    if val < min_val {
        return err(name + " too small")
    }
    if val > max_val {
        return err(name + " too large")
    }
    return ok(val)
}

fn require(condition, message) {
    # Assert a condition, return error if false
    if not condition {
        return err(message)
    }
    return ok(true)
}

# ============================================
# SECTION 4: NEURAL NETWORK HELPERS
# ============================================

fn nn_relu(x) {
    if x > 0 { return x }
    return 0
}

fn nn_leaky_relu(x, alpha) {
    if x > 0 { return x }
    return alpha * x
}

fn nn_sigmoid(x) {
    return 1.0 / (1.0 + exp(-x))
}

fn nn_tanh_approx(x) {
    let e_pos = exp(x)
    let e_neg = exp(-x)
    return (e_pos - e_neg) / (e_pos + e_neg)
}

fn nn_softmax(arr) {
    # Softmax with numerical stability
    let max_val = gpu_max(arr)
    mut exp_sum = 0.0
    mut shifted = []
    for val in arr {
        let e = exp(val - max_val)
        shifted = shifted + [e]
        exp_sum = exp_sum + e
    }
    mut result = []
    for e in shifted {
        result = result + [e / exp_sum]
    }
    return result
}

fn nn_cross_entropy(predicted, actual) {
    # Cross-entropy loss
    let eps = 0.0000000001
    mut loss = 0.0
    for i in 0..len(predicted) {
        loss = loss - actual[i] * log(predicted[i] + eps)
    }
    return loss
}

fn nn_mse(predicted, actual) {
    # Mean squared error
    mut sum_sq = 0.0
    for i in 0..len(predicted) {
        let diff = predicted[i] - actual[i]
        sum_sq = sum_sq + diff * diff
    }
    return sum_sq / len(predicted)
}

fn nn_accuracy(predicted, actual) {
    # Classification accuracy (argmax comparison)
    let pred_class = gpu_argmax(predicted)
    let true_class = gpu_argmax(actual)
    if pred_class == true_class {
        return 1.0
    }
    return 0.0
}

# ============================================
# SECTION 5: UTILITY FUNCTIONS
# ============================================

fn linspace(start, stop, n) {
    # Generate n evenly spaced values from start to stop
    if n <= 1 {
        return [start]
    }
    let step = (stop - start) / (n - 1)
    mut result = []
    for i in 0..n {
        result = result + [start + i * step]
    }
    return result
}

fn arange(start, stop, step) {
    # Generate values from start to stop with given step
    mut result = []
    mut current = start
    while current < stop {
        result = result + [current]
        current = current + step
    }
    return result
}

fn zeros_array(n) {
    # Create array of n zeros
    mut result = []
    for i in 0..n {
        result = result + [0.0]
    }
    return result
}

fn ones_array(n) {
    # Create array of n ones
    mut result = []
    for i in 0..n {
        result = result + [1.0]
    }
    return result
}

fn random_array(n) {
    # Create array of n random values [0, 1)
    mut result = []
    for i in 0..n {
        result = result + [random()]
    }
    return result
}

fn clip(val, min_val, max_val) {
    # Clip value to range
    if val < min_val { return min_val }
    if val > max_val { return max_val }
    return val
}

fn map_array(arr, f) {
    # Map function over array
    mut result = []
    for val in arr {
        result = result + [f(val)]
    }
    return result
}

fn filter_array(arr, predicate) {
    # Filter array by predicate
    mut result = []
    for val in arr {
        if predicate(val) {
            result = result + [val]
        }
    }
    return result
}

fn reduce_array(arr, f, initial) {
    # Reduce array with function
    mut acc = initial
    for val in arr {
        acc = f(acc, val)
    }
    return acc
}

fn zip_arrays(a, b) {
    # Zip two arrays together
    mut n = len(a)
    if len(b) < n {
        n = len(b)
    }
    mut result = []
    for i in 0..n {
        result = result + [[a[i], b[i]]]
    }
    return result
}

fn enumerate_array(arr) {
    # Return array of [index, value] pairs
    mut result = []
    for i in 0..len(arr) {
        result = result + [[i, arr[i]]]
    }
    return result
}

fn reverse_array(arr) {
    # Reverse array
    mut result = []
    for i in 0..len(arr) {
        result = result + [arr[len(arr) - 1 - i]]
    }
    return result
}

fn flatten_one(nested) {
    # Flatten nested array by one level
    # Assumes all items are arrays - concatenates them
    mut result = []
    for item in nested {
        for sub in item {
            result = result + [sub]
        }
    }
    return result
}

fn all_true(arr) {
    # Check if all elements are truthy
    for val in arr {
        if not val {
            return false
        }
    }
    return true
}

fn any_true(arr) {
    # Check if any element is truthy
    for val in arr {
        if val {
            return true
        }
    }
    return false
}

fn count_if(arr, predicate) {
    # Count elements matching predicate
    mut count = 0
    for val in arr {
        if predicate(val) {
            count = count + 1
        }
    }
    return count
}

fn find_index(arr, predicate) {
    # Find first index matching predicate, or -1
    for i in 0..len(arr) {
        if predicate(arr[i]) {
            return i
        }
    }
    return -1
}

fn take_n(arr, n) {
    # Take first n elements
    if n >= len(arr) {
        return arr
    }
    mut result = []
    for i in 0..n {
        result = result + [arr[i]]
    }
    return result
}

fn drop_n(arr, n) {
    # Drop first n elements
    if n >= len(arr) {
        return []
    }
    mut result = []
    for i in n..len(arr) {
        result = result + [arr[i]]
    }
    return result
}

# ============================================
# PRINT LOADING MESSAGE
# ============================================
print("NSL Extensions v1.0.0 loaded successfully")
